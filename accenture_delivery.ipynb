{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a258d43-2a1c-49a9-b83f-fa35682b30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_url = \"\"\n",
    "index_name = \"summary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef120c5b-5ff9-40ab-afa5-0253e65f4a27",
   "metadata": {},
   "source": [
    "## Redis Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fa32d5-13e8-4c09-bc71-d38fce242273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "pdf_folder_path = 'pdfs'\n",
    "\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cde7a40-df04-4f55-ada3-462605008e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1024, chunk_overlap = 40)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f4c4be-4021-4631-a277-3d260eddb869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.redis import Redis\n",
    "schema_name = \"summary_schema.yaml\"\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "rds = Redis.from_documents(all_splits,\n",
    "                           embeddings,\n",
    "                           redis_url=redis_url,\n",
    "                           index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e984de53-5eff-46b4-b3b5-556c5b7e0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds.write_schema(\"summary_schema.yaml\") ## Use this index for chatbot deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c34d7-2c59-4ad2-b4a4-41b851a816dd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639522ae-d7e8-4886-9673-366c64c2391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.llms import HuggingFaceTextGenInference\n",
    "from langchain.chains import AnalyzeDocumentChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c20cc-c35b-47cf-8b53-8abc3c4a18a9",
   "metadata": {},
   "source": [
    "## Initialize the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c884f1-1d1a-4a6a-a891-05e74f20d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inference_server_url = \"\"\n",
    "llm = HuggingFaceTextGenInference(\n",
    "    inference_server_url=inference_server_url,\n",
    "    max_new_tokens=512,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.175\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac52a9-39a5-4c5f-8017-1bb02bb190ab",
   "metadata": {},
   "source": [
    "## Generate conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816159f-621a-4795-a4b5-84c84fba3415",
   "metadata": {},
   "source": [
    "#### Performant with mistrial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c87ab44-d86c-47ff-9165-82cccd178845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(topic):\n",
    "    prompt_template = \"\"\"Use the context below to write a 400 word blog post about the topic below:\n",
    "    Context: {context}\n",
    "    Topic: {topic}\n",
    "    Blog post:\"\"\"\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \n",
    "                                                   \"topic\"]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "    docs = rds.similarity_search(topic, k=4)\n",
    "    inputs = [{\"context\": doc.page_content, \n",
    "               \"topic\": topic} for doc in docs]\n",
    "    gen = chain.apply(inputs)\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14091327-bbb1-4f8e-9231-46c4b6704937",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate(\"Langchain Concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ba0803f-f086-445f-afe9-718aaa13dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = output[2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b08133e-590c-4c02-9249-85d51938432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Understanding Langchain Concepts\\n\\nUnderstanding Langchain Concepts\\n\\nLangchain is an open-source library that provides tools for data augmentation in natural language processing (NLP) tasks. It uses generative models to compress longer documents by summarizing them into shorter versions while preserving their meaning. In this blog post, we will explore some of the key concepts behind Langchain and its applications.\\n\\nData Augmentation\\n\\nData augmentation is the process of generating new training examples from existing ones. This technique is commonly used in NLP tasks such as text classification, sentiment analysis, and machine translation. By increasing the size of the training dataset, data augmentation helps improve model performance and reduce overfitting.\\n\\nGenerative Models\\n\\nGenerative models are a class of machine learning algorithms that generate new samples based on a probability distribution learned from the training data. They differ from discriminative models, which learn to distinguish between different categories or classes. Examples of generative models include variational autoencoders (VAEs), generative adversarial networks (GANs), and transformer models.\\n\\nSummarization\\n\\nSummarization is the task of extracting important information from a longer document and presenting it in a shorter form. There are two types of summarization: extractive and abstractive. Extractive summarization involves selecting relevant sentences or phrases from the original document, while abstractive summarization generates new sentences that convey the same meaning as the original document.\\n\\nLangchain Architecture\\n\\nThe Langchain architecture consists of three main components: the input processor, the generative model, and the output processor. The input processor preprocesses the input text and converts it into a format suitable for the generative model. The generative model then generates a summary of the input text using a probabilistic model. Finally, the output processor formats the generated summary back into a human-readable text.\\n\\nApplications of Langchain\\n\\nLangchain has several applications in various domains, including:\\n\\n1. Text Summarization: Langchain can be used to automatically generate summaries of long documents, news articles, and reports.\\n2. Question Answering: Langchain can help answer questions by providing concise answers based on the input text.\\n3. Chatbots: Langchain can be integrated into chatbots to provide more personalized responses to user queries.\\n4. Information Retrieval'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e032db7-ef22-453c-9c9c-bace600d065e",
   "metadata": {},
   "source": [
    "## Summary Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4ff26-3a6d-4e77-a854-bb48509716bd",
   "metadata": {},
   "source": [
    "#### Perrformant with mistrial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f45f53-8215-490d-87cd-ce122a47a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(topic):\n",
    "    prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "    {text}\n",
    "\n",
    "\n",
    "    CONCISE SUMMARY IN GERMAN:\"\"\"\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "    summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "    summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)\n",
    "    db_retriever = rds.as_retriever()\n",
    "    langchain_qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=db_retriever)\n",
    "    relevant_data = langchain_qa(topic)\n",
    "    summary = summarize_document_chain.run(relevant_data['result'])\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b77b1b8a-7503-4a66-ba89-0f8892b0c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4403ecbc-d677-4c2c-97a2-a8b80961b650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    Langchain ist eine öffentliche Quellbibliothek, die Werkzeuge zur Vergrößerung von Daten in natürlicher Sprachverarbeitung (NLP)-Aufgaben anbietet. Sie nutzt generative Modelle, um längere Dokumente durch Zusammenfassungen in kürzere Versionen zu kompressieren, ohne deren Bedeutung zu verlieren. In diesem Blogpost werden einige Schlüsselkonzepte hinter Langchain und ihre Anwendungen erörtert.\\n\\n    Datenerweiterung\\n\\n    Datenerweiterung ist die Prozedur von existierenden Beispielen neuen Trainingsbeispielen zu generieren. Diese Technik wird häufig in NLP-Aufgaben wie Textklassifizierung, Stimmungsanalyse und Übersetzung verwendet. Durch den Erhöhung des Trainingsdatasets helft Datenerweiterung die Modellperformance zu verbessern und Überfitting zu reduzieren.\\n\\n    Generative Modelle\\n\\n    Generative Modelle sind eine Klasse Maschinenlernung-Algorithmus, die neue Proben auf einer Wahrscheinlichkeitsverteilung aus dem Trainingdatum lernen und dann auf dieser Basis neue Sammlungen erzeugen. Sie unterscheiden sich von diskriminativen Modeln, die zwischen verschiedenen Kategorien oder Klassen lernen. Beispiele für Generative Modelle sind Variabelautomatische Encoder (VAEs), generative Adversarielle Netze (GANs) und Transformer-Modelle.\\n\\n    Zusammenfassung\\n\\n    Die Architektur von Langchain besteht aus drei Hauptkomponenten: dem Eingabeprozessor, dem generativen Modell und dem Ausgangsprozessor. Der Eingabeprozessor vorbereitet den Eingabetext und konvertiert ihn in einen Format, das für das generative Modell geeignet ist. Das generative Modell dann erzeugt eine Zusammenfassung des Eingabetextes mit Hilfe einer wahrscheinlichen Modell. Schließlich wird der Ausgangsprozessor benutzt,'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c105dc6-5b83-4cd1-8917-4d5469b34baa",
   "metadata": {},
   "source": [
    "## Document Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d1d0ff9-32c8-4b85-a688-bc246eb90d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_gen = f'Blog Post: {generate} \\n\\n\\n\\n\\n Blog Post Summary in German: {summary}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df88c374-7443-476d-a0a6-88624e141a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blog Post:  Understanding Langchain Concepts\n",
      "\n",
      "Understanding Langchain Concepts\n",
      "\n",
      "Langchain is an open-source library that provides tools for data augmentation in natural language processing (NLP) tasks. It uses generative models to compress longer documents by summarizing them into shorter versions while preserving their meaning. In this blog post, we will explore some of the key concepts behind Langchain and its applications.\n",
      "\n",
      "Data Augmentation\n",
      "\n",
      "Data augmentation is the process of generating new training examples from existing ones. This technique is commonly used in NLP tasks such as text classification, sentiment analysis, and machine translation. By increasing the size of the training dataset, data augmentation helps improve model performance and reduce overfitting.\n",
      "\n",
      "Generative Models\n",
      "\n",
      "Generative models are a class of machine learning algorithms that generate new samples based on a probability distribution learned from the training data. They differ from discriminative models, which learn to distinguish between different categories or classes. Examples of generative models include variational autoencoders (VAEs), generative adversarial networks (GANs), and transformer models.\n",
      "\n",
      "Summarization\n",
      "\n",
      "Summarization is the task of extracting important information from a longer document and presenting it in a shorter form. There are two types of summarization: extractive and abstractive. Extractive summarization involves selecting relevant sentences or phrases from the original document, while abstractive summarization generates new sentences that convey the same meaning as the original document.\n",
      "\n",
      "Langchain Architecture\n",
      "\n",
      "The Langchain architecture consists of three main components: the input processor, the generative model, and the output processor. The input processor preprocesses the input text and converts it into a format suitable for the generative model. The generative model then generates a summary of the input text using a probabilistic model. Finally, the output processor formats the generated summary back into a human-readable text.\n",
      "\n",
      "Applications of Langchain\n",
      "\n",
      "Langchain has several applications in various domains, including:\n",
      "\n",
      "1. Text Summarization: Langchain can be used to automatically generate summaries of long documents, news articles, and reports.\n",
      "2. Question Answering: Langchain can help answer questions by providing concise answers based on the input text.\n",
      "3. Chatbots: Langchain can be integrated into chatbots to provide more personalized responses to user queries.\n",
      "4. Information Retrieval \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Blog Post Summary in German: \n",
      "\n",
      "    Langchain ist eine öffentliche Quellbibliothek, die Werkzeuge zur Vergrößerung von Daten in natürlicher Sprachverarbeitung (NLP)-Aufgaben anbietet. Sie nutzt generative Modelle, um längere Dokumente durch Zusammenfassungen in kürzere Versionen zu kompressieren, ohne deren Bedeutung zu verlieren. In diesem Blogpost werden einige Schlüsselkonzepte hinter Langchain und ihre Anwendungen erörtert.\n",
      "\n",
      "    Datenerweiterung\n",
      "\n",
      "    Datenerweiterung ist die Prozedur von existierenden Beispielen neuen Trainingsbeispielen zu generieren. Diese Technik wird häufig in NLP-Aufgaben wie Textklassifizierung, Stimmungsanalyse und Übersetzung verwendet. Durch den Erhöhung des Trainingsdatasets helft Datenerweiterung die Modellperformance zu verbessern und Überfitting zu reduzieren.\n",
      "\n",
      "    Generative Modelle\n",
      "\n",
      "    Generative Modelle sind eine Klasse Maschinenlernung-Algorithmus, die neue Proben auf einer Wahrscheinlichkeitsverteilung aus dem Trainingdatum lernen und dann auf dieser Basis neue Sammlungen erzeugen. Sie unterscheiden sich von diskriminativen Modeln, die zwischen verschiedenen Kategorien oder Klassen lernen. Beispiele für Generative Modelle sind Variabelautomatische Encoder (VAEs), generative Adversarielle Netze (GANs) und Transformer-Modelle.\n",
      "\n",
      "    Zusammenfassung\n",
      "\n",
      "    Die Architektur von Langchain besteht aus drei Hauptkomponenten: dem Eingabeprozessor, dem generativen Modell und dem Ausgangsprozessor. Der Eingabeprozessor vorbereitet den Eingabetext und konvertiert ihn in einen Format, das für das generative Modell geeignet ist. Das generative Modell dann erzeugt eine Zusammenfassung des Eingabetextes mit Hilfe einer wahrscheinlichen Modell. Schließlich wird der Ausgangsprozessor benutzt,\n"
     ]
    }
   ],
   "source": [
    "print(doc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127308a5-42e7-4f5f-b41a-0b8545c22a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
